{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el archivo de reviews scrapeadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "flybondi_data = '../data/final_combined_reviews.csv'\n",
    "df = pd.read_csv(flybondi_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empezamos a limpiar.\n",
    "\n",
    "1. Remover columnas in√∫tiles y filas duplicadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the unnamed columns which are trash\n",
    "df_cleaned = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# remove duplicates\n",
    "df_cleaned = df_cleaned.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpiamos ratings para que tenga unico formato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>experience</th>\n",
       "      <th>review_text</th>\n",
       "      <th>likes</th>\n",
       "      <th>review_title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>Silvia Elena P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Excelente el servicio. Tripulaci√≥n s√∫per atent...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Altamente recomendable. Equipo amable y eficie...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>Martina B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Todo un desastre, el vuelo de ida se atraso 3 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peor experiencia</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>carolina c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Que les puedo decir que no sepamos: es una aer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP AIRLINES</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>Jime Ache ü§©</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quiero destacar que todo fue impecable en el v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Todo fue un 10</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Cami D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Desastre. Nos cambiaron el horario de vuelo mu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Desastre</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>Pablo Romero</td>\n",
       "      <td>1 opini√≥n</td>\n",
       "      <td>Si quieren saber el significado de las palabra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SERVICIO NEFASTO FLYBONDI</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>Aur√©lien C</td>\n",
       "      <td>6 opiniones</td>\n",
       "      <td>Compr√© un primer boleto, el cheque se cerr√≥ co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Estafa total</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>Marcos Medvescig</td>\n",
       "      <td>1 opini√≥n</td>\n",
       "      <td>La peor experience. Me cambiarion el horario d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>La peor basura voladora del mundo</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>Silvia Elena Perez Sbarbatti</td>\n",
       "      <td>1 opini√≥n</td>\n",
       "      <td>La empresa cumpli√≥ con las condiciones pautada...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Excelente la puntualidad, la atenci√≥n y el sev...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>Nazarena Sebastianelli</td>\n",
       "      <td>2 opiniones</td>\n",
       "      <td>Realmente lo pensar√≠a dos veces antes de volve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Realmente lo pensar√≠a dos veces antes‚Ä¶</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1061 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name   experience  \\\n",
       "1300                Silvia Elena P          NaN   \n",
       "1301                     Martina B          NaN   \n",
       "1302                    carolina c          NaN   \n",
       "1303                   Jime Ache ü§©          NaN   \n",
       "1304                        Cami D          NaN   \n",
       "...                            ...          ...   \n",
       "2357                  Pablo Romero    1 opini√≥n   \n",
       "2358                    Aur√©lien C  6 opiniones   \n",
       "2359              Marcos Medvescig    1 opini√≥n   \n",
       "2360  Silvia Elena Perez Sbarbatti    1 opini√≥n   \n",
       "2361        Nazarena Sebastianelli  2 opiniones   \n",
       "\n",
       "                                            review_text  likes  \\\n",
       "1300  Excelente el servicio. Tripulaci√≥n s√∫per atent...    NaN   \n",
       "1301  Todo un desastre, el vuelo de ida se atraso 3 ...    NaN   \n",
       "1302  Que les puedo decir que no sepamos: es una aer...    NaN   \n",
       "1303  Quiero destacar que todo fue impecable en el v...    NaN   \n",
       "1304  Desastre. Nos cambiaron el horario de vuelo mu...    NaN   \n",
       "...                                                 ...    ...   \n",
       "2357  Si quieren saber el significado de las palabra...    NaN   \n",
       "2358  Compr√© un primer boleto, el cheque se cerr√≥ co...    NaN   \n",
       "2359  La peor experience. Me cambiarion el horario d...    NaN   \n",
       "2360  La empresa cumpli√≥ con las condiciones pautada...    NaN   \n",
       "2361  Realmente lo pensar√≠a dos veces antes de volve...    NaN   \n",
       "\n",
       "                                           review_title  rating  \n",
       "1300  Altamente recomendable. Equipo amable y eficie...     5.0  \n",
       "1301                                   Peor experiencia     1.0  \n",
       "1302                                       HDP AIRLINES     1.0  \n",
       "1303                                     Todo fue un 10     5.0  \n",
       "1304                                           Desastre     1.0  \n",
       "...                                                 ...     ...  \n",
       "2357                          SERVICIO NEFASTO FLYBONDI     1.0  \n",
       "2358                                       Estafa total     1.0  \n",
       "2359                  La peor basura voladora del mundo     1.0  \n",
       "2360  Excelente la puntualidad, la atenci√≥n y el sev...     5.0  \n",
       "2361             Realmente lo pensar√≠a dos veces antes‚Ä¶     3.0  \n",
       "\n",
       "[1061 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['rating_cleaned'] = df_cleaned['rating'].astype(str).str.extract(r'(\\d+\\.?\\d*)').astype(float)\n",
    "df_cleaned = df_cleaned.drop(columns=['rating'])\n",
    "df_cleaned = df_cleaned.rename(columns={'rating_cleaned': 'rating'})\n",
    "df_cleaned['rating'] = df_cleaned['rating'].fillna(1.0)\n",
    "\n",
    "df_cleaned.iloc[1300:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenamos titulos con reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>experience</th>\n",
       "      <th>likes</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>Pablo Romero</td>\n",
       "      <td>1 opini√≥n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>servicio nefasto flybondi. si quieren saber el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>Aur√©lien C</td>\n",
       "      <td>6 opiniones</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>estafa total. compr√© un primer boleto, el cheq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>Marcos Medvescig</td>\n",
       "      <td>1 opini√≥n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>la peor basura voladora del mundo. la peor exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>Silvia Elena Perez Sbarbatti</td>\n",
       "      <td>1 opini√≥n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>excelente la puntualidad, la atenci√≥n y el sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>Nazarena Sebastianelli</td>\n",
       "      <td>2 opiniones</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>realmente lo pensar√≠a dos veces antes‚Ä¶. realme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name   experience  likes  rating  \\\n",
       "2357                  Pablo Romero    1 opini√≥n    NaN     1.0   \n",
       "2358                    Aur√©lien C  6 opiniones    NaN     1.0   \n",
       "2359              Marcos Medvescig    1 opini√≥n    NaN     1.0   \n",
       "2360  Silvia Elena Perez Sbarbatti    1 opini√≥n    NaN     5.0   \n",
       "2361        Nazarena Sebastianelli  2 opiniones    NaN     3.0   \n",
       "\n",
       "                                                 review  \n",
       "2357  servicio nefasto flybondi. si quieren saber el...  \n",
       "2358  estafa total. compr√© un primer boleto, el cheq...  \n",
       "2359  la peor basura voladora del mundo. la peor exp...  \n",
       "2360  excelente la puntualidad, la atenci√≥n y el sev...  \n",
       "2361  realmente lo pensar√≠a dos veces antes‚Ä¶. realme...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['review'] = df_cleaned['review_title'].fillna('') + '. ' + df_cleaned['review_text'].fillna('')\n",
    "df_cleaned = df_cleaned.drop(columns=['review_title', 'review_text'])\n",
    "df_cleaned['review'] = df_cleaned['review'].str.lower()\n",
    "df_cleaned.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos reviews que tengan nombre repetido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_258607/2606435315.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_cleaned = df_cleaned.groupby('name', group_keys=False).apply(longest_review)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1902, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def longest_review(group):\n",
    "    return group.loc[group['review'].str.len().idxmax()]\n",
    "\n",
    "df_cleaned = df_cleaned.groupby('name', group_keys=False).apply(longest_review)\n",
    "\n",
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "df_cleaned.head()\n",
    "\n",
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpiamos \"Likes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>experience</th>\n",
       "      <th>likes</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22fortinero</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>malisima. malisimo..la peor.\\nvuando fuimos pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23russellv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>one of the worst we have flown. we have flown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>terrible service. flight was first delayed 25 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5travellers602013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rubbish low cost airline. bought 6 tickets via...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>885David_R885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>not refunding cancelled flights. not refunding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>–í–∞–ª–µ—Ä–∏—è –®—É–ª—å–≥–∞</td>\n",
       "      <td>1 rese√±a</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>. el vuelo fue reprogramado sin informarnos al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>–í–∏–∫–∞ –ú–µ–≥–∞–ª–∏—Å</td>\n",
       "      <td>3 rese√±as</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>. me gustar√≠a decirles a todos: nunca compren ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>–î–∞—Ä—å—è –í–µ–Ω–µ–¥–∏–∫—Ç–æ–≤–∞</td>\n",
       "      <td>1 rese√±a</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>. esta empresa ya hace un a√±o que no viene, fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>◊ô◊°◊û◊ô◊ü ◊ô</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dont buy here!!!! scam. it's completely ridicu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>ÏµúÏäπÌòÑ</td>\n",
       "      <td>4 rese√±as ¬∑ 2 fotos</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>. nunca, nunca, nunca utilices esta aerol√≠nea....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1902 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name           experience  likes  rating  \\\n",
       "0           22fortinero                  NaN      0     1.0   \n",
       "1            23russellv                  NaN      0     2.0   \n",
       "2               4family                  NaN      0     1.0   \n",
       "3     5travellers602013                  NaN      0     1.0   \n",
       "4         885David_R885                  NaN      0     1.0   \n",
       "...                 ...                  ...    ...     ...   \n",
       "1897     –í–∞–ª–µ—Ä–∏—è –®—É–ª—å–≥–∞             1 rese√±a      3     1.0   \n",
       "1898       –í–∏–∫–∞ –ú–µ–≥–∞–ª–∏—Å            3 rese√±as      2     1.0   \n",
       "1899  –î–∞—Ä—å—è –í–µ–Ω–µ–¥–∏–∫—Ç–æ–≤–∞             1 rese√±a      5     1.0   \n",
       "1900            ◊ô◊°◊û◊ô◊ü ◊ô                  NaN      0     1.0   \n",
       "1901                ÏµúÏäπÌòÑ  4 rese√±as ¬∑ 2 fotos      1     1.0   \n",
       "\n",
       "                                                 review  \n",
       "0     malisima. malisimo..la peor.\\nvuando fuimos pe...  \n",
       "1     one of the worst we have flown. we have flown ...  \n",
       "2     terrible service. flight was first delayed 25 ...  \n",
       "3     rubbish low cost airline. bought 6 tickets via...  \n",
       "4     not refunding cancelled flights. not refunding...  \n",
       "...                                                 ...  \n",
       "1897  . el vuelo fue reprogramado sin informarnos al...  \n",
       "1898  . me gustar√≠a decirles a todos: nunca compren ...  \n",
       "1899  . esta empresa ya hace un a√±o que no viene, fu...  \n",
       "1900  dont buy here!!!! scam. it's completely ridicu...  \n",
       "1901  . nunca, nunca, nunca utilices esta aerol√≠nea....  \n",
       "\n",
       "[1902 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['likes'] = df_cleaned['likes'].fillna(0)\n",
    "df_cleaned['likes'] = df_cleaned['likes'].astype(int)\n",
    "\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una funci√≥n que transforma la experience y los likes en un √∫nico formato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_experience(experience):\n",
    "    resenas = 0\n",
    "    fotos = 0\n",
    "    local_guide = 0\n",
    "\n",
    "    if pd.isna(experience):\n",
    "        return resenas, fotos, local_guide\n",
    "\n",
    "    if 'Local Guide' in experience:\n",
    "        local_guide = 1\n",
    "\n",
    "    resenas_match = re.search(r'(\\d+[\\.,]?\\d*) (rese√±as|opini√≥n|opiniones)', experience)\n",
    "    if resenas_match:\n",
    "        resenas = int(resenas_match.group(1).replace('.', '').replace(',', '.'))\n",
    "\n",
    "    fotos_match = re.search(r'(\\d+[\\.,]?\\d*) fotos', experience)\n",
    "    if fotos_match:\n",
    "        fotos = int(fotos_match.group(1).replace('.', '').replace(',', '.'))\n",
    "\n",
    "    return resenas, fotos, local_guide\n",
    "\n",
    "df_cleaned[['given_reviews', 'pictures', 'local_guide']] = df_cleaned['experience'].apply(\n",
    "    lambda x: pd.Series(parse_experience(x))\n",
    ")\n",
    "\n",
    "df_cleaned[['given_reviews', 'pictures', 'local_guide']]\n",
    "df_cleaned = df_cleaned.drop(columns=['experience'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>given_reviews</th>\n",
       "      <th>pictures</th>\n",
       "      <th>local_guide</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>relevance_score_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.001745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.004072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.002909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.004479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1902 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      likes  given_reviews  pictures  local_guide  relevance_score  \\\n",
       "0         0              0         0            0             0.00   \n",
       "1         0              0         0            0             0.00   \n",
       "2         0              0         0            0             0.00   \n",
       "3         0              0         0            0             0.00   \n",
       "4         0              0         0            0             0.00   \n",
       "...     ...            ...       ...          ...              ...   \n",
       "1897      3              0         0            0             0.90   \n",
       "1898      2              3         0            0             2.10   \n",
       "1899      5              0         0            0             1.50   \n",
       "1900      0              0         0            0             0.00   \n",
       "1901      1              4         2            0             2.31   \n",
       "\n",
       "      relevance_score_normalized  \n",
       "0                       0.000000  \n",
       "1                       0.000000  \n",
       "2                       0.000000  \n",
       "3                       0.000000  \n",
       "4                       0.000000  \n",
       "...                          ...  \n",
       "1897                    0.001745  \n",
       "1898                    0.004072  \n",
       "1899                    0.002909  \n",
       "1900                    0.000000  \n",
       "1901                    0.004479  \n",
       "\n",
       "[1902 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_relevance(row, W_l=0.3, W_r=0.5, W_p=0.005, W_lg=0.5):\n",
    "    relevance = (\n",
    "        W_l * row['likes'] +\n",
    "        W_r * row['given_reviews'] +\n",
    "        W_p * row['pictures'] +\n",
    "        W_lg * row['local_guide']\n",
    "    )\n",
    "    return relevance\n",
    "\n",
    "df_cleaned['relevance_score'] = df_cleaned.apply(calculate_relevance, axis=1)\n",
    "df_cleaned['relevance_score_normalized'] = (df_cleaned['relevance_score'] - df_cleaned['relevance_score'].min()) / (df_cleaned['relevance_score'].max() - df_cleaned['relevance_score'].min())\n",
    "\n",
    "df_cleaned[['likes', 'given_reviews', 'pictures', 'local_guide', 'relevance_score', 'relevance_score_normalized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>likes</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>given_reviews</th>\n",
       "      <th>pictures</th>\n",
       "      <th>local_guide</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>relevance_score_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22fortinero</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>malisima. malisimo..la peor.\\nvuando fuimos pe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23russellv</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>one of the worst we have flown. we have flown ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4family</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>terrible service. flight was first delayed 25 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5travellers602013</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rubbish low cost airline. bought 6 tickets via...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>885David_R885</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>not refunding cancelled flights. not refunding...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>–í–∞–ª–µ—Ä–∏—è –®—É–ª—å–≥–∞</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>. el vuelo fue reprogramado sin informarnos al...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.001745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>–í–∏–∫–∞ –ú–µ–≥–∞–ª–∏—Å</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>. me gustar√≠a decirles a todos: nunca compren ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.004072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>–î–∞—Ä—å—è –í–µ–Ω–µ–¥–∏–∫—Ç–æ–≤–∞</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>. esta empresa ya hace un a√±o que no viene, fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.002909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>◊ô◊°◊û◊ô◊ü ◊ô</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dont buy here!!!! scam. it's completely ridicu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>ÏµúÏäπÌòÑ</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>. nunca, nunca, nunca utilices esta aerol√≠nea....</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.004479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1902 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  likes  rating  \\\n",
       "0           22fortinero      0     1.0   \n",
       "1            23russellv      0     2.0   \n",
       "2               4family      0     1.0   \n",
       "3     5travellers602013      0     1.0   \n",
       "4         885David_R885      0     1.0   \n",
       "...                 ...    ...     ...   \n",
       "1897     –í–∞–ª–µ—Ä–∏—è –®—É–ª—å–≥–∞      3     1.0   \n",
       "1898       –í–∏–∫–∞ –ú–µ–≥–∞–ª–∏—Å      2     1.0   \n",
       "1899  –î–∞—Ä—å—è –í–µ–Ω–µ–¥–∏–∫—Ç–æ–≤–∞      5     1.0   \n",
       "1900            ◊ô◊°◊û◊ô◊ü ◊ô      0     1.0   \n",
       "1901                ÏµúÏäπÌòÑ      1     1.0   \n",
       "\n",
       "                                                 review  given_reviews  \\\n",
       "0     malisima. malisimo..la peor.\\nvuando fuimos pe...              0   \n",
       "1     one of the worst we have flown. we have flown ...              0   \n",
       "2     terrible service. flight was first delayed 25 ...              0   \n",
       "3     rubbish low cost airline. bought 6 tickets via...              0   \n",
       "4     not refunding cancelled flights. not refunding...              0   \n",
       "...                                                 ...            ...   \n",
       "1897  . el vuelo fue reprogramado sin informarnos al...              0   \n",
       "1898  . me gustar√≠a decirles a todos: nunca compren ...              3   \n",
       "1899  . esta empresa ya hace un a√±o que no viene, fu...              0   \n",
       "1900  dont buy here!!!! scam. it's completely ridicu...              0   \n",
       "1901  . nunca, nunca, nunca utilices esta aerol√≠nea....              4   \n",
       "\n",
       "      pictures  local_guide  relevance_score  relevance_score_normalized  \n",
       "0            0            0             0.00                    0.000000  \n",
       "1            0            0             0.00                    0.000000  \n",
       "2            0            0             0.00                    0.000000  \n",
       "3            0            0             0.00                    0.000000  \n",
       "4            0            0             0.00                    0.000000  \n",
       "...        ...          ...              ...                         ...  \n",
       "1897         0            0             0.90                    0.001745  \n",
       "1898         0            0             2.10                    0.004072  \n",
       "1899         0            0             1.50                    0.002909  \n",
       "1900         0            0             0.00                    0.000000  \n",
       "1901         2            0             2.31                    0.004479  \n",
       "\n",
       "[1902 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>malisima. malisimo..la peor.\\nvuando fuimos pe...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one of the worst we have flown. we have flown ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>terrible service. flight was first delayed 25 ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rubbish low cost airline. bought 6 tickets via...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not refunding cancelled flights. not refunding...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>. el vuelo fue reprogramado sin informarnos al...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>. me gustar√≠a decirles a todos: nunca compren ...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>. esta empresa ya hace un a√±o que no viene, fu...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>dont buy here!!!! scam. it's completely ridicu...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>. nunca, nunca, nunca utilices esta aerol√≠nea....</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1902 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review language\n",
       "0     malisima. malisimo..la peor.\\nvuando fuimos pe...       es\n",
       "1     one of the worst we have flown. we have flown ...       en\n",
       "2     terrible service. flight was first delayed 25 ...       en\n",
       "3     rubbish low cost airline. bought 6 tickets via...       en\n",
       "4     not refunding cancelled flights. not refunding...       en\n",
       "...                                                 ...      ...\n",
       "1897  . el vuelo fue reprogramado sin informarnos al...       es\n",
       "1898  . me gustar√≠a decirles a todos: nunca compren ...       es\n",
       "1899  . esta empresa ya hace un a√±o que no viene, fu...       es\n",
       "1900  dont buy here!!!! scam. it's completely ridicu...       en\n",
       "1901  . nunca, nunca, nunca utilices esta aerol√≠nea....       es\n",
       "\n",
       "[1902 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)  # Returns a language code (e.g., 'en', 'es')\n",
    "    except LangDetectException:\n",
    "        return 'unknown'  # Handle cases where language detection fails\n",
    "\n",
    "df_cleaned['language'] = df_cleaned['review'].apply(detect_language)\n",
    "\n",
    "# Display the DataFrame with the new 'language' column\n",
    "df_cleaned[['review', 'language']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "from googletrans import LANGUAGES\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "def translate_to_spanish(text, src_lang):\n",
    "    try:\n",
    "        translation = translator.translate(text, src=src_lang, dest='es')  # 'es' for Spanish\n",
    "        return translation.text\n",
    "    except Exception as e:\n",
    "        print(\"could not translate: \", text)\n",
    "        print(f\"Error translating: {e}\")\n",
    "        return text\n",
    "\n",
    "def translate_non_spanish(text, lang):\n",
    "    if lang != 'es' and lang != 'unknown':\n",
    "        return translate_to_spanish(text, lang)\n",
    "    return text\n",
    "\n",
    "df_cleaned['review_translated'] = df_cleaned.apply(\n",
    "    lambda row: translate_non_spanish(row['review'], row['language']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_cleaned[['review', 'language', 'review_translated']]\n",
    "\n",
    "# Optionally, save the updated DataFrame\n",
    "output_file_translated_reviews = '../data/cleaned_with_translated_non_es_reviews.csv'\n",
    "df_cleaned.to_csv(output_file_translated_reviews, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22fortinero</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>malisima malisimola peor\\nvuando perdi dia hot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23russellv</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>uno peores voladohemos volado cientos aerol√≠ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4family</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>terrible servicioel vuelo retras√≥ primera vez ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5travellers602013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>basco aerol√≠nea bajo costocompr√© 6 boletos tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>885David_R885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no reembolsar vuelos canceladosno reembolsar v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>–í–∞–ª–µ—Ä–∏—è –®—É–ª—å–≥–∞</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>vuelo reprogramado informarnos respecto pagam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>–í–∏–∫–∞ –ú–µ–≥–∞–ª–∏—Å</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>gustar√≠a decirles nunca compren mosca flybond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>–î–∞—Ä—å—è –í–µ–Ω–µ–¥–∏–∫—Ç–æ–≤–∞</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>empresa hace a√±o viene p√©rdida tiempo venir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>◊ô◊°◊û◊ô◊ü ◊ô</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>estafaes completamente rid√≠culo vuelo retras√≥ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>ÏµúÏäπÌòÑ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>nunca nunca nunca utilices aerol√≠nea\\ncuando ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1902 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  rating  relevance_score  \\\n",
       "0           22fortinero     1.0         0.000000   \n",
       "1            23russellv     2.0         0.000000   \n",
       "2               4family     1.0         0.000000   \n",
       "3     5travellers602013     1.0         0.000000   \n",
       "4         885David_R885     1.0         0.000000   \n",
       "...                 ...     ...              ...   \n",
       "1897     –í–∞–ª–µ—Ä–∏—è –®—É–ª—å–≥–∞     1.0         0.001745   \n",
       "1898       –í–∏–∫–∞ –ú–µ–≥–∞–ª–∏—Å     1.0         0.004072   \n",
       "1899  –î–∞—Ä—å—è –í–µ–Ω–µ–¥–∏–∫—Ç–æ–≤–∞     1.0         0.002909   \n",
       "1900            ◊ô◊°◊û◊ô◊ü ◊ô     1.0         0.000000   \n",
       "1901                ÏµúÏäπÌòÑ     1.0         0.004479   \n",
       "\n",
       "                                                 review  \n",
       "0     malisima malisimola peor\\nvuando perdi dia hot...  \n",
       "1     uno peores voladohemos volado cientos aerol√≠ne...  \n",
       "2     terrible servicioel vuelo retras√≥ primera vez ...  \n",
       "3     basco aerol√≠nea bajo costocompr√© 6 boletos tra...  \n",
       "4     no reembolsar vuelos canceladosno reembolsar v...  \n",
       "...                                                 ...  \n",
       "1897   vuelo reprogramado informarnos respecto pagam...  \n",
       "1898   gustar√≠a decirles nunca compren mosca flybond...  \n",
       "1899        empresa hace a√±o viene p√©rdida tiempo venir  \n",
       "1900  estafaes completamente rid√≠culo vuelo retras√≥ ...  \n",
       "1901   nunca nunca nunca utilices aerol√≠nea\\ncuando ...  \n",
       "\n",
       "[1902 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "\n",
    "flybondi_data = '../data/cleaned_with_translated_non_es_reviews.csv'\n",
    "df_cleaned = pd.read_csv(flybondi_data)\n",
    "\n",
    "spanish_stopwords = set(stopwords.words('spanish'))\n",
    "punctuation = string.punctuation + '¬°'\n",
    "\n",
    "def remove_emojis(text):\n",
    "    # Regular expression pattern to match emojis\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        \"\\U00002702-\\U000027B0\"  # other symbols\n",
    "        \"\\U000024C2-\\U0001F251\"  # enclosed characters\n",
    "        \"]+\", flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove emojis\n",
    "    text = remove_emojis(text)\n",
    "    # Remove punctuation by translating all punctuation characters to None\n",
    "    text = text.translate(str.maketrans('', '', punctuation))\n",
    "    # Remove Spanish stopwords by iterating through the words\n",
    "    for stopword in spanish_stopwords:\n",
    "        text = text.replace(f\" {stopword} \", \" \")  # Replace only whole words\n",
    "    return text\n",
    "\n",
    "df_cleaned['review_processed'] = df_cleaned['review_translated'].apply(preprocess_text)\n",
    "\n",
    "df_cleaned[['review_translated', 'review_processed']]\n",
    "# remove review_translated column\n",
    "df_cleaned = df_cleaned.drop(columns=['review_translated', 'language', 'relevance_score', 'review', 'given_reviews', 'pictures', 'local_guide', 'likes'])\n",
    "#rename review_processed to review\n",
    "df_cleaned = df_cleaned.rename(columns={'review_processed': 'review'})\n",
    "df_cleaned = df_cleaned.rename(columns={'relevance_score_normalized': 'relevance_score'})\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizador\n",
    "Ahora que tenemos un dataset con todas las reviews limpias y traducidas procedemos a lemmatizar el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaquin/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: 392kB [00:00, 51.9MB/s]                    \n",
      "2024-10-18 21:08:58 INFO: Downloaded file to /home/joaquin/stanza_resources/resources.json\n",
      "2024-10-18 21:08:58 INFO: Downloading default packages for language: es (Spanish) ...\n",
      "2024-10-18 21:09:00 INFO: File exists: /home/joaquin/stanza_resources/es/default.zip\n",
      "2024-10-18 21:09:06 INFO: Finished downloading models and saved to /home/joaquin/stanza_resources\n",
      "2024-10-18 21:09:06 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: 392kB [00:00, 42.5MB/s]                    \n",
      "2024-10-18 21:09:06 INFO: Downloaded file to /home/joaquin/stanza_resources/resources.json\n",
      "2024-10-18 21:09:07 INFO: Loading these models for language: es (Spanish):\n",
      "====================================\n",
      "| Processor    | Package           |\n",
      "------------------------------------\n",
      "| tokenize     | combined          |\n",
      "| mwt          | combined          |\n",
      "| pos          | combined_charlm   |\n",
      "| lemma        | combined_nocharlm |\n",
      "| constituency | combined_charlm   |\n",
      "| depparse     | combined_charlm   |\n",
      "| sentiment    | tass2020_charlm   |\n",
      "| ner          | conll02           |\n",
      "====================================\n",
      "\n",
      "2024-10-18 21:09:07 INFO: Using device: cuda\n",
      "2024-10-18 21:09:07 INFO: Loading: tokenize\n",
      "/home/joaquin/.local/lib/python3.10/site-packages/stanza/models/tokenization/trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-18 21:09:08 INFO: Loading: mwt\n",
      "/home/joaquin/.local/lib/python3.10/site-packages/stanza/models/mwt/trainer.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-18 21:09:08 INFO: Loading: pos\n",
      "/home/joaquin/.local/lib/python3.10/site-packages/stanza/models/pos/trainer.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "/home/joaquin/.local/lib/python3.10/site-packages/stanza/models/common/pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
      "/home/joaquin/.local/lib/python3.10/site-packages/stanza/models/common/char_model.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-18 21:09:08 INFO: Loading: lemma\n",
      "/home/joaquin/.local/lib/python3.10/site-packages/stanza/models/lemma/trainer.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-18 21:09:08 INFO: Loading: constituency\n",
      "/home/joaquin/.local/lib/python3.10/site-packages/stanza/models/constituency/base_trainer.py:87: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-18 21:09:08 INFO: Loading: depparse\n",
      "/home/joaquin/.local/lib/python3.10/site-packages/stanza/models/depparse/trainer.py:194: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-18 21:09:09 INFO: Loading: sentiment\n",
      "/home/joaquin/.local/lib/python3.10/site-packages/stanza/models/classifiers/trainer.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-18 21:09:09 INFO: Loading: ner\n",
      "/home/joaquin/.local/lib/python3.10/site-packages/stanza/models/ner/trainer.py:197: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-18 21:09:09 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "df = df_cleaned\n",
    "\n",
    "stanza.download('es')\n",
    "nlp = stanza.Pipeline('es')\n",
    "\n",
    "def lemmatize_spanish(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    return ' '.join([word.lemma for sent in doc.sentences for word in sent.words])\n",
    "\n",
    "# Apply the lemmatization function only to Spanish reviews\n",
    "df['review'] = df.apply(\n",
    "    lambda row: lemmatize_spanish(row['review']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Optionally, save the updated DataFrame with lemmatized reviews\n",
    "output_file_lemmatized_reviews = '../data/cleaned_with_lemmatized_reviews.csv'\n",
    "df.to_csv(output_file_lemmatized_reviews, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "System Python",
   "language": "python",
   "name": "system_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
